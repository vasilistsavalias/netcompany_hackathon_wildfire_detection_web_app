# Remove the version tag as it's now obsolete in modern Docker Compose
services:
  # Backend service configuration - handles our Flask application and ML model
  backend:
    build: ./machine_learning  # Points to the directory containing our Dockerfile
    ports:
      # Bind to localhost only for security
      # Format is "host_port:container_port"
      - "127.0.0.1:8080:8080"
    
    environment:
      # Environment variables for our application
      DATABASE_URL: ${DATABASE_URL}  # Database connection string
      FLASK_SECRET_KEY: ${FLASK_SECRET_KEY}  # Secret key for Flask sessions
      PYTHONUNBUFFERED: 1  # Ensures Python output isn't buffered, giving us immediate logs
      FLASK_APP: run.py  # Tells Flask which file to run
      FLASK_RUN_HOST: 0.0.0.0  # Allows connections from outside the container
      FLASK_RUN_PORT: 8080  # Port our application listens on
      TZ: UTC  # Set timezone to UTC for consistent timestamps
    
    # Ensures database is healthy before starting the backend
    depends_on:
      db:
        condition: service_healthy
    
    # Health check configuration to monitor our application
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s  # Check every 30 seconds
      timeout: 10s   # Wait up to 10 seconds for response
      retries: 3     # Try 3 times before marking unhealthy
      start_period: 60s  # Give 60s for initial startup (model loading)
    
    # Resource limits to prevent memory issues with ML model
    deploy:
      resources:
        limits:
          memory: 2G    # Allow up to 2GB memory for ML model
          cpus: '1.0'   # Allow up to 1 full CPU core
    
    # Restart policy for reliability
    restart: unless-stopped
    
    # Logging configuration to prevent disk space issues
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    
    # Run our application using gunicorn for production-grade serving
    command: [
      "gunicorn",
      "--bind", "0.0.0.0:8080",
      "--workers", "1",
      "--timeout", "120",
      "--worker-class", "gthread",
      "--threads", "4",
      "run:app"
    ]

  # Database service configuration
  db:
    build: ./database # Changed
    #image: postgres:alpine # Use this if you DONT have init.sql
    ports:
      - "5432:5432"  # Optional: for external access
    environment:
      POSTGRES_USER: ${POSTGRES_USER}  # Use environment variable
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}  # Use environment variable
      POSTGRES_DB: ${POSTGRES_DB}  # Use environment variable
    volumes:
      - db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"


        
  frontend:  # Add the frontend service
    build: ./front_end
    ports:
      - "80:80"  # Expose port 80 (or a different port if you prefer)
    depends_on:
      - backend # Optional
    restart: unless-stopped

# Define named volumes for persistent data
volumes:
  db_data:  # This volume persists PostgreSQL data between container restarts